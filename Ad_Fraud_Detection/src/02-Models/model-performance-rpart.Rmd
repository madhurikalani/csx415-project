---
title: "model-performance-rpart"
author: "Madhuri Kalani"
date: "April 21, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## Loading the Project

The first step of model training is to load the project. It includes installing all the necessary libraries and data munging to prepare the training and test data sets, doing exploratory data analysis to study the data and feature selection.

```{r p0, echo =FALSE, warning=FALSE, include=FALSE}

setwd("~/Madhuri stuff/Data_Science_Intro_R/Ad_Fraud_Detection")

library('ProjectTemplate')
load.project()

library('caret')



```

## Model Training using rpart

The caret package in R provides a powerful framework for growing classification trees.

```{r c1, warning = FALSE}

#Tree Model to Classify - rpart


train_control <- trainControl(method="cv", number=3)
model_rpart <- train(as.factor(is_attributed)~app + channel + ip +device + os + click_time, data=df.train, method="rpart", trControl=train_control)
```

### Summary of Trained Rpart
```{r p10,echo =FALSE , warning=FALSE}
# Results of Model Training
model_rpart
```
### Plotting the Trained Model

```{r p11,echo =FALSE , warning=FALSE}
plot(model_rpart)

```
### Fitting the Trained rpart Model
```{r p12,echo =FALSE , warning=FALSE}
predict_rpart <- predict(model_rpart, df.test)
sum(as.integer(predict_rpart))
print(predict_rpart)
```
 ## Evaluation 
### Step 1 Building a Confusion Matrix


It is a tabular representation of Actual vs Predicted values. This helps to find the accuracy of the model and avoid overfitting. 
```{r p13,echo =FALSE , warning=FALSE}
print("Confusion Matrix for tree: rpart")
cm_rpart <- confusionMatrix(table(as.factor(test$is_attributed),predict_rpart))
cm_rpart
```
### Step 2 Finding Cohen's Kappa

```{r p14,echo =FALSE , warning=FALSE}
print("Kappa value for tree: rpart")
cm_rpart$overall[2]
```
### Step 3 Finding Accuracy Value
```{r p15,echo =FALSE , warning=FALSE}

print("Accuracy value for tree: rpart")
cm_rpart$overall[1]
```
### Step 4 Building a ROC Curve

An ROC curve demonstrates several things for 2-class classification algorithms:

It shows the tradeoff between sensitivity and specificity (any increase in sensitivity will be accompanied by a decrease in specificity).
The closer the curve follows the left-hand border and then the top border of the ROC space, the more accurate the test.
The closer the curve comes to the 45-degree diagonal of the ROC space, the less accurate the test.

```{r p16,echo =FALSE,  warning = FALSE, message = FALSE}

library(pROC)
plot(roc(df.test$is_attributed, as.numeric(predict_rpart), direction="<"),
      col="yellow", lwd=3, main="ROC Curve for Tree: Rpart")


```


### Saving the model object as RDS to be used in a package
```{r p17,echo =FALSE,  warning = FALSE}
setwd("~/Madhuri stuff/Data_Science_Intro_R/Ad_Fraud_Detection/pkgs/AdFraud/data")
saveRDS(model_rpart, "model_rpart.rds")

```

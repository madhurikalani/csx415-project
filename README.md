# AdFraud_Click_Detection
## 1	Business Problem Statement

TData (big data services provider) handles 3 billion clicks per day, of which over 90% are fraudulent. They came in contact with a new agency which helped them to detect and prevent ad fraud by installing anti-fraud technology and but soon they started receiving complaints/feedback from users on how ads are often interruptive, annoying and irrelevant. Soon they realized that something was wrong with their technology and digital advertising. 

## 2	Project Description and Objectives

## 2.1	Description

TData (big data services provider) covers 70% of active mobile devices in Japan. They handle 3 billion clicks per day, of which over 90% are fraudulent. The technology they built with the help of an agency was not helpful in filtering the traffic.

Soon after they started receiving complaints from the app users about irrelevant ad clicks, they setup a team to dive deep into the problem. 

To begin, team also noticed some suspicious activity and decided to evaluate the ad-campaigns.

The process they want to follow is to track user clicks across their portfolio and identify IP address that produce a lot of clicks but never end up installing the app. 
The clicks made here are non-human and are generated by (ro)bots which are computer programs that can mimic human clicking patterns and Web surfing.

These illegitimate bots usually do so with the purpose to delude digital ad metrics and steal from ad-buyers. These bots are employed for malicious intent and are an immense problem for digital ad buyers and the digital ad industry at large.

Once they have this information, they can block those IP addresses and devices. The objective here is also to find out which users actually end up installing the app.


## 2.2	Objectives

1.	Identify IP address that produce a lot of clicks but never end up installing the app.
 
2.	Users actually end up installing the app.

3.	Mr. Mazel wants to ensure that $10 million digital budget was being used most effectively.

4.	Reduce 11% rate of fraud traffic by  atleast 50% to start with from the already-filtered traffic


## 3 Data Objective

The objective is to predict whether a user will download an application after clicking a mobile advertisement.

Looking at the data it looks like a classification problem that outputs two classes. 
The training data and test data consists of 184 million and 1.8 million rows respectively. 

## 4 Training Data
Each row of training data contains a click record, with the following features:

1. ip: ip address of click.
2. app: app id for marketing.
3. device: device type id of user mobile phone (e.g., iphone 6 plus, huawei mate 7, etc.)
4. os: os version id of user mobile phone
5. channel: channel id of mobile ad publisher
6. click_time: timestamp of click (UTC)
7. attributed_time: if user download the app for after clicking an ad, this is the time of the app download
8. is_attributed: the target that is to be predicted, indicating the app was downloaded (1= app downloaded, 0= not downloaded)

Please note that ip, app, device, os, and channel are encoded. 

Currently, I am beginning my analysis with 1 million rows of training data.

The test data is similar, with the following
differences:
1. click_id: reference for making predictions
2. is_attributed: not included
